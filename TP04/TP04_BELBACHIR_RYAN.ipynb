{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2CS SIQ2-SIL2 TP04. Naïve Bayes\n",
    "\n",
    "Dans ce TP, nous allons traiter Naïve Bayes. C'est le seul algorithme dans notre programme qui crée un modèle génératif (en plus des auto-encodeurs)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Binôme 01** : Ryan BELBACHIR\n",
    "- **Groupe** : SIL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.23.4', '1.5.1', '3.6.2')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy             as np\n",
    "import pandas            as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "np        .__version__ , \\\n",
    "pd        .__version__ , \\\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAPPEL**\n",
    "\n",
    "Tout le monde connait le théorème de Bayes pour calculer la probabilité conditionnelle d'un évennement $A$ sachant un autre $B$ (si vous ne le connaissez pas; vous n'appartenez pas à tout le monde) : \n",
    "$$ P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$\n",
    "\n",
    "Pour appliquer ce théorème sur un problème d'appentissage automatique, l'idée est simple ; Etant donné une caractéristique $f$ et la sortie $y$ qui peut avoir la classe $c$ : \n",
    "- Remplacer $A$ par $y=c$\n",
    "- Remplacer $B$ par $f$ \n",
    "On aura l'équation : \n",
    "$$ P(y=c|f) = \\frac{P(y=c)P(f|y=c)}{P(f)}$$\n",
    "\n",
    "On appelle : \n",
    "- $P(y=c|f)$ postérieure \n",
    "- $P(y=c)$ antérieure\n",
    "- $P(f|y=c)$ vraisemblance\n",
    "- $P(f)$ évidence \n",
    "\n",
    "Ici, on estime la probablité d'une classe $c$ sachant une caractéristique $f$ en utilisant des données d'entrainement. Maintenant, on veut estimer la probabilité d'une classe $c$ sachant un vecteur de caractéristiques $\\overrightarrow{f} = \\{f_1, ..., f_L\\}$ : \n",
    "$$ P(y=c|\\overrightarrow{f}) = \\frac{P(y=c)P(\\overrightarrow{f}|y=c)}{P(f)}$$\n",
    "\n",
    "Etant donnée plusieurs classes $c_j$, la classe choisie $\\hat{c}$ est celle avec la probabilité maximale \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k|\\overrightarrow{f})$$\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\frac{P(y=c_k)P(\\overrightarrow{f}|y=c_k)}{P(f)}$$\n",
    "On supprime l'évidence pour cacher le crime : $P(f)$ ne dépend pas de $c_k$ et elle est postive, donc ça ne va pas affecter la fonction $\\max$.\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k)P(\\overrightarrow{f}|y=c_k)$$\n",
    "\n",
    "Pour calculer $P(\\overrightarrow{f}|y=c_k)$, on va utiliser une properiété naïve (d'où vient le nom Naive Bayes) : on suppose l'indépendence conditionnelle entre les caractéristiques $f_j$. \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k) \\prod\\limits_{f_j \\in \\overrightarrow{f}} P(f_j|y=c_k)$$\n",
    "\n",
    "Pour éviter la disparition de la probabilité (multiplication et représentation de virgule flottante sur machine), on transforme vers l'espace logarithme.\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Réalisation des algorithmes\n",
    "\n",
    "Pour estimer la vraisemblance, il existe plusieurs modèles (lois):\n",
    "- **Loi multinomiale :** pour les caracétristiques nominales\n",
    "- **Loi de Bernoulli :** lorsqu'on est interressé par l'apparence d'une caractéristique ou non (binaire)\n",
    "- **Loi normale :** pour les caractéristiques numériques\n",
    "\n",
    "Dans ce TP, nous allons implémenter Naive Bayes pour les caractéristiques nominales (loi multinomiale). \n",
    "Dans notre modèle, nous voulons stocker les statistiques et pas les probabilités. \n",
    "L'intérêt est de faciliter la mise à jours des statistiques (si par exemple, nous avons un autre dataset et nous voulons enrichir le modèle ; dans e cas, il suffit d'ajouter les statistiques du nouveau dataset)\n",
    "\n",
    "Ici, nous allons utiliser le dataset \"jouer\" (utilisé dans la plupart des cours) contenant des caractéristiques nominales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temps</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidite</th>\n",
       "      <th>vent</th>\n",
       "      <th>jouer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>douce</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>chaude</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temps temperature humidite vent jouer\n",
       "0   ensoleile      chaude    haute  non   non\n",
       "1   ensoleile      chaude    haute  oui   non\n",
       "2     nuageux      chaude    haute  non   oui\n",
       "3    pluvieux       douce    haute  non   oui\n",
       "4    pluvieux     fraiche  normale  non   oui\n",
       "5    pluvieux     fraiche  normale  oui   non\n",
       "6     nuageux     fraiche  normale  oui   oui\n",
       "7   ensoleile       douce    haute  non   non\n",
       "8   ensoleile     fraiche  normale  non   oui\n",
       "9    pluvieux       douce  normale  non   oui\n",
       "10  ensoleile       douce  normale  oui   oui\n",
       "11    nuageux       douce    haute  oui   oui\n",
       "12    nuageux      chaude  normale  non   oui\n",
       "13   pluvieux       douce    haute  oui   non"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jouer   = pd.read_csv('data/jouer.csv')\n",
    "\n",
    "X_jouer = jouer.iloc[:, :-1].values # Premières colonnes \n",
    "Y_jouer = jouer.iloc[:,  -1].values # Dernière colonne \n",
    "\n",
    "# Afficher le dataset \"jouer\"\n",
    "jouer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1. Entraînement de la probabilité antérieure\n",
    "\n",
    "Etant donné le vecteur de sortie $Y$, la probabilité de chaque classe (différentes valeurs de $Y$) est calulée comme :\n",
    "\n",
    "$$p(c_k) = \\frac{|\\{y / y \\in Y \\text{ et } y = c_k\\}|}{|Y|}$$\n",
    "\n",
    "\n",
    "La fonction doit récupérer des statistiques afin de pouvoir calculer la probabilité antérieure de chaque classe. Donc, elle doit retourner  :\n",
    "- Un vecteur contenant les noms des classes\n",
    "- Un vecteur contenant les nombres d'occurrences de chaque classe dans le premier vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['non', 'oui'], dtype=object), array([5, 9]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Stastistiques sur la probabilité antérieure\n",
    "def stat_anterieure(Y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    cls  = np.unique(Y) # le vecteur des classes\n",
    "    freq = list(map(lambda x: np.count_nonzero(Y==x),cls))\n",
    "    # compléter à partir d'ici\n",
    "    return cls, np.array(freq)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array(['non', 'oui'], dtype=object), array([5, 9]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "stat_anterieure(Y_jouer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2. Entraînement de la probabilité de vraissemblance (loi multinomiale)\n",
    "\n",
    "Notre modèle doit garder le nombre des différentes valeurs d'une caractéristique $A$ et le nombre de ces valeurs dans chaque classe.\n",
    "Donc, étant donné un vecteur d'une caractéristique $A= X[:,j]$, un autre des $Y$ et un $C$ contenant la liste des classes, la fonction d'entraînement doit retourner : \n",
    "- $V$ : un vecteur contenant les différentes catégories de $A$ (c'est déjà fait)\n",
    "- Une matrice contenant le nombre d'occurrences de chaque catégorie de $V$ dans chaque classe  : \n",
    "   - Les lignes représentent les catégories $v \\in V$ de la caréctéristique $A$\n",
    "   - Les colonnes représentent les classes $c \\in C$ de $Y$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
       " array([[3, 2],\n",
       "        [0, 4],\n",
       "        [2, 3]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Statistiques de vraissemblance (une seule caractéristique)\n",
    "def stat_vraissemblance_1(A: np.ndarray, \n",
    "                          Y: np.ndarray, \n",
    "                          C: np.ndarray\n",
    "                         ) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    freq = []\n",
    "    V = np.unique(A) # Catégories de la caractéristique A\n",
    "    # compléter à partir d'ici\n",
    "    for weather in V:\n",
    "       freq.append(\n",
    "           list(map(lambda y : \n",
    "                    list(map(lambda z: np.count_nonzero(y==z),C)),list(map(lambda x : Y[x] ,list(np.where(A==weather))))))[0]) #Could have used extend\n",
    "    \n",
    "    return V, np.array(freq)\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
    "#  array([[3, 2],\n",
    "#         [0, 4],\n",
    "#         [2, 3]]))\n",
    "#---------------------------------------------------------------------\n",
    "C_t = np.array(['non', 'oui'])\n",
    "stat_vraissemblance_1(X_jouer[:, 0], Y_jouer, C_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3. Entraînement loi multinomiale\n",
    "\n",
    "**Rien à programmer ici**\n",
    "\n",
    "Notre modèle ($\\theta_{X, C}$) doit garder des statistiques sur les classes et aussi sur chaque catégorie de chaque caractéristique. Pour ce faire, nous allons représenter $\\theta$ comme un vecteur : \n",
    "- $\\theta[N+1]$ est un vecteur de $N$ éléments représentant des statistiques sur chaque caractéristique $j$, plus un élément (le dernier) pour les statistiques sur les classes.\n",
    "- Chaque élément est un dictionnaire (HashMap en Java)\n",
    "- Un élément des caractéristiques contient deux clés : \n",
    "    - **val** : pour récupérer la liste des noms des catégories de la caractéristique\n",
    "    - **freq**: pour récupérer une matrice représentant la fréquence de chaque caractéristique dans chaque classe\n",
    "- Un élément des classes contient deux clés : \n",
    "    - **cls** : pour récupérer la liste des noms des classes\n",
    "    - **freq**: pour récupérer la liste des fréquences de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
       "  'freq': array([[3, 2],\n",
       "         [0, 4],\n",
       "         [2, 3]])},\n",
       " {'val': array(['chaude', 'douce', 'fraiche'], dtype=object),\n",
       "  'freq': array([[2, 2],\n",
       "         [2, 4],\n",
       "         [1, 3]])},\n",
       " {'val': array(['haute', 'normale'], dtype=object),\n",
       "  'freq': array([[4, 3],\n",
       "         [1, 6]])},\n",
       " {'val': array(['non', 'oui'], dtype=object),\n",
       "  'freq': array([[2, 6],\n",
       "         [3, 3]])},\n",
       " {'cls': array(['non', 'oui'], dtype=object), 'freq': array([5, 9])}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La fonction qui entraine Théta sur plusieurs caractéristiques\n",
    "# Rien à programmer ici\n",
    "# Notre théta est une liste des dictionnaires;\n",
    "# chaque dictionnaire contient la liste des catégories et la matrice des fréquences dela caractéristique respective à la colonne de X\n",
    "# On ajoute les statistiques antérieures des classes à la fin de résultat\n",
    "def entrainer_multi(X: np.ndarray, \n",
    "                    Y: np.ndarray\n",
    "                   ) -> np.ndarray: \n",
    "    \n",
    "    Theta   = []\n",
    "    \n",
    "    stats_c = {}\n",
    "    stats_c['cls'], stats_c['freq'] =  stat_anterieure(Y)\n",
    "    \n",
    "    for j in range(X.shape[1]): \n",
    "        stats = {}\n",
    "        stats['val'], stats['freq'] =  stat_vraissemblance_1(X[:, j], Y, stats_c['cls'])\n",
    "        Theta.append(stats)\n",
    "    \n",
    "    Theta.append(stats_c)\n",
    "    return Theta\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# [{'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
    "#   'freq': array([[3, 2],\n",
    "#          [0, 4],\n",
    "#          [2, 3]])},\n",
    "#  {'val': array(['chaude', 'douce', 'fraiche'], dtype=object),\n",
    "#   'freq': array([[2, 2],\n",
    "#          [2, 4],\n",
    "#          [1, 3]])},\n",
    "#  {'val': array(['haute', 'normale'], dtype=object),\n",
    "#   'freq': array([[4, 3],\n",
    "#          [1, 6]])},\n",
    "#  {'val': array(['non', 'oui'], dtype=object),\n",
    "#   'freq': array([[2, 6],\n",
    "#          [3, 3]])},\n",
    "#  {'cls': array(['non', 'oui'], dtype=object), 'freq': array([5, 9])}]\n",
    "#---------------------------------------------------------------------\n",
    "Theta_jouer = entrainer_multi(X_jouer, Y_jouer)\n",
    "\n",
    "Theta_jouer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4. Estimation de la probabilité de vraissemblance (loi multinomiale)\n",
    "L'équation pour estimer la vraisemblance \n",
    "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}|}{|\\{y = c_k\\}|}$$\n",
    "\n",
    "\n",
    "Dans le cas d'une valeur $v$ qui n'existe pas dans le dataset d'entrainnement ou qui n'existe pas pour une classe donnée mais ui existe dans le dataset de test, nous aurons une probabilité nulle. \n",
    "Afin de régler ce problème, nous pouvons appliquer une fonction de lissage qui attribue une petite probabilité aux données non vues dans l'entraînement. \n",
    "Le lissage que nous allons utiliser est celui de Lidstone. \n",
    "Lorsque $\\alpha = 1$, il est appelé lissage de Laplace.\n",
    "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}| + \\alpha}{|\\{y = c_k\\}| + \\alpha * |V|}$$\n",
    "Où: \n",
    "- $\\alpha$ est une valeur donnée \n",
    "- $V$ est l'ensemble des différentes valeurs de $f_j$ (le vocabulaire; les catégories)\n",
    "\n",
    "Etant donné : \n",
    "- $\\theta_j$ les paramètres de la caractéristique $j$ représentées comme dictionnaire\n",
    "    - **val** : pour récupérer la liste des noms des catégories de la caractéristique (vocabulaire $V$)\n",
    "    - **freq**: pour récupérer une matrice représentant la fréquence de chaque caractéristique dans chaque classe. C'est une matrice $|V|\\times|C|$\n",
    "- $v$ la valeur de la caractéristique $j$ utilisée pour calculer les probabilités\n",
    "- $\\theta_c$ les paramètres des classes $C$ représentées comme dictionnaire\n",
    "    - **cls** : pour récupérer la liste des noms des classes\n",
    "    - **freq**: pour récupérer la liste des fréquences des classes\n",
    "    \n",
    "Cette fonction doit retourner : \n",
    "- Une liste $P[|C|]$ contenant les probabilités de la catégorie $v$ de $X_j$ sur toutes les classes $C$ \n",
    "- Elle doit prendre en considération le cas où la valeur $v$ n'existe pas dans le modèle entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.4       , 0.33333333]), array([0.125     , 0.08333333]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculer la vraissamblance d'une valeur donnée\n",
    "def P_vraiss_multi(Theta_j: Dict[str, np.ndarray], \n",
    "                   Theta_c: Dict[str, np.ndarray], \n",
    "                   v      : str, \n",
    "                   alpha  : float = 0.\n",
    "                  ) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    \n",
    "    #une liste des indices où se trouve la valeur v dans Theta_j[\"val\"]\n",
    "    ind = np.where(Theta_j['val'] == v)[0] \n",
    "    # compléter à partir d'ici\n",
    "    e=Theta_c['cls']\n",
    "    p=np.zeros(len(e))\n",
    "    \n",
    "    for idx,j in enumerate(e):\n",
    "        nom=alpha\n",
    "        if(len(ind)): \n",
    "            nom+=Theta_j['freq'][ind,idx]\n",
    "        p[idx]=nom/(Theta_c['freq'][idx]+alpha*len(Theta_j['val']))\n",
    "    return p\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([0.4       , 0.33333333]), array([0.125     , 0.08333333]))\n",
    "#---------------------------------------------------------------------\n",
    "# Calcul :\n",
    "# La probabilité de jouer si temps = pluvieux \n",
    "# P(temps = pluvieux | jouer=oui) = (nbr(temps=pluvieux et jouer=oui)+alpha)/(nbr(jour=oui) + alpha * nbr_diff(temps)))\n",
    "# P(temps = pluvieux | jouer=oui) = (3 + 0)/(9 + 0) ==> 3 est le nombre de différentes valeurs de temps (entrainnement)\n",
    "# P(temps = pluvieux | jouer=oui) = 4/12 ==> 0.33333333333333333333333333333333333~\n",
    "\n",
    "# La probabilité de jouer si temps = neigeux \n",
    "# P(temps = neigeux | jouer=oui) = (nbr(temps=neigeux et jouer=oui)+alpha)/(nbr(jouer=oui) + alpha * nbr_diff(temps)))\n",
    "# P(temps = neigeux | jouer=oui) = (0 + 1)/(9 + 3) ==> 3 est le nombre de différentes valeurs de temps (entrainnement)\n",
    "# P(temps = neigeux | jouer=oui) = 1/13 ==> 0.0833333333333333333333333333333333333~\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "P_vraiss_multi(Theta_jouer[0], Theta_jouer[-1], 'pluvieux'), \\\n",
    "P_vraiss_multi(Theta_jouer[0], Theta_jouer[-1], 'neigeux', alpha=1.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5. Prédiction de la classe (loi multinomiale)\n",
    "Revenons maintenant à notre équation de prédiction \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n",
    "\n",
    "- On doit prédire un seule échantillon $x$. \n",
    "- La fonction doit retourner un vecteur des log-probabilité des classes\n",
    "- Si anter=false donc on n'utilise pas la probabilité antérieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Prédiction des log des probabilités\n",
    "def predire(x: np.ndarray, Theta: List[Dict[str, np.ndarray]], alpha: float = 1., anter: bool = True) -> float:\n",
    "    pred=np.zeros(2)\n",
    "    if(anter):\n",
    "        pred=(np.log(Theta[-1]['freq']/np.sum(Theta[-1]['freq'][:])))\n",
    "    for i in range(len(Theta)-1):\n",
    "        pred+=np.log(P_vraiss_multi(Theta[i],Theta[-1],x[i],alpha))\n",
    "    return pred\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))\n",
    "#---------------------------------------------------------------------\n",
    "predire(['pluvieux', 'fraiche', 'normale', 'oui'], Theta_jouer), \\\n",
    "predire(['pluvieux', 'fraiche', 'normale', 'oui'], Theta_jouer, anter=False) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6. Regrouper en une classe (loi multinomiale)\n",
    "\n",
    "**Rien à programmer ici**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oui', 'non']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NBMultinom(object): \n",
    "    \n",
    "    def __init__(self, alpha=1.): \n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def entrainer(self, X, Y):\n",
    "        self.Theta = entrainer_multi(X, Y)\n",
    "    \n",
    "    def predire(self, X, anter=True, prob=False): \n",
    "        Y_pred = []\n",
    "        cls = self.Theta[-1]['cls']\n",
    "        for i in range(len(X)): \n",
    "            log_prob = predire(X[i,:], self.Theta, alpha=self.alpha, anter=anter)\n",
    "            if prob:\n",
    "                Y_pred.append(np.max(log_prob))\n",
    "            else:\n",
    "                Y_pred.append(cls[np.argmax(log_prob)])\n",
    "        return Y_pred\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# ['oui', 'non']\n",
    "#---------------------------------------------------------------------\n",
    "notre_modele = NBMultinom()\n",
    "notre_modele.entrainer(X_jouer, Y_jouer)\n",
    "X_test = np.array([\n",
    "    ['neigeux', 'fraiche', 'normale', 'oui'],\n",
    "    ['neigeux', 'fraiche', 'haute'  , 'oui']\n",
    "])\n",
    "notre_modele.predire(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Application et analyse\n",
    "\n",
    "**Il n'y a rien à programmer ici.**\n",
    "\n",
    "Le but de cette section est de mener des expérimentations afin de bien comprendre les concepts vus dans le cours.\n",
    "Aussi, elle nous assiste à comprendre l'effet des différents paramètres.\n",
    "En plus, la discussion des différentes expérimentations peut améliorer l'aspect analytique chez l'étudient.\n",
    "\n",
    "### II.1. Probabilité antérieure \n",
    "\n",
    "Nous voulons tester l'effet de la probabilité antérieure.\n",
    "Pour ce faire, nous avons entraîné deux modèles :\n",
    "1. Avec probabilité antérieure\n",
    "1. Sans probabilité antérieure (Il considère une distribution uniforme des classes)\n",
    "\n",
    "Pour tester si les modèles ont bien s'adapter au dataset d'entraînement, nous allons les tester sur le même dataset et calculer le rapport de classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec probabilité antérieure (a priori)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Sans probabilité antérieure (a priori)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       0.67      0.80      0.73         5\n",
      "         oui       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.77      0.79      0.78        14\n",
      "weighted avg       0.80      0.79      0.79        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AVEC Scikit-learn\n",
    "# ===================\n",
    "from sklearn.naive_bayes   import CategoricalNB\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics       import classification_report\n",
    "\n",
    "nb_avec     = CategoricalNB(alpha=1.0, fit_prior=True )\n",
    "nb_sans     = CategoricalNB(alpha=1.0, fit_prior=False)\n",
    "\n",
    "enc         = OrdinalEncoder()\n",
    "X_jouer_enc = enc.fit_transform(X_jouer)\n",
    "nb_avec.fit(X_jouer_enc, Y_jouer)\n",
    "nb_sans.fit(X_jouer_enc, Y_jouer)\n",
    "\n",
    "Y_pred_avec = nb_avec.predict(X_jouer_enc)\n",
    "Y_pred_sans = nb_sans.predict(X_jouer_enc)\n",
    "\n",
    "# AVEC notre modèle (juste pour voir comment l'utiliser)\n",
    "# =======================================================\n",
    "#notre_modele = NBMultinom()\n",
    "#notre_modele.entrainer(X_jouer, Y_jouer)\n",
    "#Y_notre_ant = notre_modele.predire(X_jouer)\n",
    "#Y_notre_sans_ant = notre_modele.predire(X_jouer, anter=False) \n",
    "\n",
    "# Le rapport de classification\n",
    "\n",
    "\n",
    "print( 'Avec probabilité antérieure (a priori)'  )\n",
    "print(classification_report(Y_jouer, Y_pred_avec))\n",
    "\n",
    "print( 'Sans probabilité antérieure (a priori)'  )\n",
    "print(classification_report(Y_jouer, Y_pred_sans))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "    \n",
    "- Que remarquez-vous ?\n",
    "- Est-ce que la probabilité antérieure est importante dans ce cas ?\n",
    "- Comment cette probabilité affecte le résultat ?\n",
    "- Quand est-ce que nous sommes sûrs que l'utilisation de cette probabilité est inutile ?\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "- Je remarque que les performances du modèle sans probabilité antérieure sont relativement faibles en comparaison avec le modèle qui utilise la probabilité antérieure.\n",
    "\n",
    "    Cela peut être dû au fait que le modèle sans probabilité antérieure suppose une distribution uniforme des classes, ce qui peut ne pas être le cas dans la réalité. Cela peut également expliquer pourquoi le modèle sans probabilité antérieure a obtenu une précision plus faible pour la classe \"non\" par rapport au modèle avec probabilité antérieure.\n",
    "\n",
    "    En revanche, le modèle avec probabilité antérieure a obtenu des scores de précision et de rappel parfaits pour la classe \"non\". Cela peut s'expliquer par le fait que le nombre d'exemples de la classe \"non\" est relativement petit dans l'ensemble de données et que la probabilité antérieure a aidé à mieux estimer la probabilité de cette classe.\n",
    "\n",
    "    En somme, ces résultats soulignent l'importance de la probabilité antérieure dans le modèle de classification bayésien naïf et comment cela peut aider à améliorer la performance de l'algorithme.\n",
    "\n",
    "- Ces résultats soulignent l'importance de la probabilité antérieure dans le modèle de classification bayésien naïf et comment cela peut aider à améliorer la performance de l'algorithme et cela du moins dans ce cas.\n",
    "\n",
    "- Elle affecte le résultat de la manière suivante :\n",
    "\n",
    "    * Si nous avons une forte hypothèse sur la distribution des classes, nous pouvons utiliser une probabilité antérieure plus forte pour donner plus de poids à cette hypothèse et ainsi améliorer la performance de l'algorithme.\n",
    "    * Si nous avons peu ou pas de connaissances préalables sur la distribution des classes, nous pouvons utiliser une distribution uniforme des classes, qui donnera des poids égaux à toutes les classes et ainsi éviter de biaiser le modèle dans une direction ou une autre.\n",
    "\n",
    "    En résumé, la probabilité antérieure affecte la manière dont le modèle interprète les données et utilise les connaissances préalables pour estimer les probabilités de chaque classe. Si nous avons des connaissances préalables fiables sur la distribution des classes, cela peut aider à améliorer la performance de l'algorithme. Sinon, nous pouvons utiliser une distribution uniforme pour éviter de biaiser le modèle dans une direction ou une autre.\n",
    "- L'utilisation de la probabilité antérieure dans le modèle de classification bayésien naïf dépend des connaissances préalables que nous avons sur la distribution des classes dans les données. Si nous n'avons pas de connaissances préalables ou si nous avons peu de connaissances fiables sur la distribution des classes, l'utilisation de la probabilité antérieure peut être inutile.\n",
    "\n",
    "    Cependant, même si nous n'avons pas de connaissances préalables sur la distribution des classes, il est toujours préférable de tester l'effet de la probabilité antérieure sur le modèle en comparant les performances avec et sans l'utilisation de cette probabilité. Si l'utilisation de la probabilité antérieure n'améliore pas significativement les performances du modèle, nous pouvons conclure qu'elle est inutile dans ce cas spécifique.\n",
    "\n",
    "    En résumé, nous pouvons être sûrs que l'utilisation de la probabilité antérieure est inutile lorsque nous n'avons pas de connaissances préalables fiables sur la distribution des classes dans les données, et que les performances du modèle ne sont pas significativement améliorées par son utilisation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Lissage\n",
    "\n",
    "Nous voulons tester l'effet de lissage de Lidstone.\n",
    "Pour ce faire, nous avons entraîné trois modèles : \n",
    "1. alpha = 1 (lissage de Laplace)\n",
    "1. alpha = 0.5\n",
    "1. alpha = 0 (sans lissage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Alpha = 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Alpha = 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jr_be\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\naive_bayes.py:627: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jr_be\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NBC_10 = CategoricalNB(alpha = 1.0 )\n",
    "NBC_05 = CategoricalNB(alpha = 0.5 )\n",
    "NBC_00 = CategoricalNB(alpha = 0.0 )\n",
    "\n",
    "NBC_10.fit( X_jouer_enc,   Y_jouer )\n",
    "NBC_05.fit( X_jouer_enc,   Y_jouer )\n",
    "NBC_00.fit( X_jouer_enc,   Y_jouer )\n",
    "\n",
    "Y_10   = NBC_10.predict(X_jouer_enc)\n",
    "Y_05   = NBC_05.predict(X_jouer_enc)\n",
    "Y_00   = NBC_00.predict(X_jouer_enc)\n",
    "\n",
    "\n",
    "print(          'Alpha = 1.0'             )\n",
    "print(classification_report(Y_jouer, Y_10))\n",
    "\n",
    "print(          'Alpha = 0.5'             )\n",
    "print(classification_report(Y_jouer, Y_05))\n",
    "\n",
    "print(          'Alpha = 0.0'             )\n",
    "print(classification_report(Y_jouer, Y_00))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "\n",
    "- Que remarquez-vous ?\n",
    "- Est-ce que le lissage affecte la performance dans ce cas ? Pourquoi ?\n",
    "- Pourquoi Scikit-learn n'accepte pas la valeur $\\alpha=0$ et affiche une alerte \"UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\" ?\n",
    "- Quelle est l'intérêt du lissage (dans le cas général) ?\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "- On remarque que quelque soit alpha, le lissage ne change rien au score f1 donc le lissage n'a pas d'effet dans ce dataset. Comme on peut aussi observer que les modèles avec lissage donnent des performances légèrement inférieures en termes de précision et de rappel par rapport au modèle sans lissage pour les classes \"oui\" et \"non\". Cela peut s'expliquer par le fait que le lissage répartit uniformément la probabilité sur toutes les catégories et peut diminuer la capacité du modèle à capturer les différences de fréquence entre les catégories. Cependant, le modèle sans lissage peut également être sensible à un manque de données, ce qui peut conduire à un surapprentissage et à une baisse des performances lorsqu'il est testé sur des données de test. Le choix de la valeur d'alpha dépend donc du nombre de données disponibles et de la complexité du modèle.\n",
    "\n",
    "- Dans ce cas, on remarque que l'effet du lissage n'est pas significatif sur la performance de la classification. Les trois modèles ont atteint une précision similaire sur l'ensemble de données de test. Cela peut s'expliquer par le fait que l'ensemble de données est relativement petit, avec seulement 14 échantillons, ce qui peut rendre difficile la détection de l'effet du lissage. De plus, les attributs ont des valeurs discrètes avec un nombre limité de catégories, ce qui réduit également l'impact du lissage.\n",
    "\n",
    "    Cependant, en général, le lissage peut améliorer la performance du modèle en évitant la sur-estimation ou la sous-estimation de certaines probabilités en raison d'une fréquence d'occurrence nulle ou très faible dans l'ensemble de données d'entraînement. Le choix de la valeur optimale d'alpha dépendra du domaine d'application et de la qualité des données disponibles.\n",
    "- Lorsqu'on utilise la formule de lissage de Lidstone avec une valeur alpha très proche de zéro, il y a un risque de division par zéro car il faut diviser par le nombre total de observations dans la classe, qui peut être nul. Cela peut provoquer des erreurs numériques et une instabilité du modèle.\n",
    "\n",
    "    Pour éviter cela, Scikit-learn utilise une valeur minimale de alpha pour s'assurer qu'il n'y aura pas de division par zéro. Cette valeur minimale est généralement très petite, mais suffisamment grande pour éviter les erreurs numériques. Ainsi, si l'utilisateur entre une valeur de alpha qui est inférieure à cette valeur minimale, Scikit-learn émet une alerte \"UserWarning\" pour avertir l'utilisateur et ajuste automatiquement la valeur de alpha à cette valeur minimale pour éviter les erreurs numériques.\n",
    "\n",
    "- Le lissage est une technique utilisée en apprentissage automatique pour éviter que les modèles de classification ne soient trop sensibles aux données d'entraînement et ne surajustent aux données. En effet, lorsque certaines classes n'apparaissent pas dans les données d'entraînement, le modèle peut avoir une probabilité nulle pour cette classe, ce qui rendrait la classification impossible. Le lissage permet de résoudre ce problème en ajoutant une petite quantité aux probabilités, ce qui donne aux classes non observées une probabilité non nulle mais faible. Cela permet au modèle de généraliser mieux aux données de test et de ne pas être trop rigide aux données d'entraînement. Le lissage de Laplace (ou Lidstone) est une technique de lissage populaire qui ajoute une petite quantité alpha aux fréquences des classes lors de l'estimation des probabilités. Aussi, en général, le lissage peut améliorer la performance du modèle en évitant la sur-estimation ou la sous-estimation de certaines probabilités en raison d'une fréquence d'occurrence nulle ou très faible dans l'ensemble de données d'entraînement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3. Comparaison avec d'autres algorithmes\n",
    "\n",
    "Naive Bayes est un algorithme puissant lorsqu'il s'agit de classer les documents textuels ; nous voulons tester cette information avec la détection de spam. \n",
    "Le dataset utilisé est [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset).\n",
    "Chaque message du dataset doit être représenté sous forme d'un modèle \"Sac à mots\" (BoW : Bag of Words).\n",
    "Dans l'entraînement, les différents mots qui s'apparaissent dans les messages (vocabulaire) sont considérés comme des caractéristiques. \n",
    "Donc, pour chaque message, la valeur de la caractéristique est la fréquence du mot dans le message. \n",
    "Par exemple, si le mot \"good\" apparait 3 fois dans le message, donc la caractéristique \"good\" aura la valeur 3 dans ce message.\n",
    "\n",
    "Notre implémentation n'est pas adéquate pour la nature de ce problème. \n",
    "Dans Scikit-learn, [sklearn.naive_bayes.CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) est similaire à notre implémentation. \n",
    "L'algorithme adéquat pour ce type de problème est [sklearn.naive_bayes.MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
    "Les algorithmes comparés :\n",
    "1. Naive Bayes (Loi Multinomiale)\n",
    "1. Naive Bayes (Loi Gaussienne)\n",
    "1. Regression logistique \n",
    "1. Arbres de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texte classe\n",
       "0  Go until jurong point, crazy.. Available only ...    ham\n",
       "1                      Ok lar... Joking wif u oni...    ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   spam\n",
       "3  U dun say so early hor... U c already then say...    ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...    ham"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lire le dataset\n",
    "messages = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
    "# renomer les caractéristiques : texte et classe\n",
    "messages = messages.rename(columns={'v1': 'classe', 'v2': 'texte'})\n",
    "# garder seulement ces deux caractéristiques\n",
    "messages = messages.filter(['texte', 'classe'])\n",
    "\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection         import train_test_split\n",
    "from sklearn.naive_bayes             import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model            import LogisticRegression\n",
    "from sklearn.tree                    import DecisionTreeClassifier\n",
    "from sklearn.metrics                 import precision_score, recall_score\n",
    "import timeit\n",
    "\n",
    "\n",
    "modeles = [\n",
    "    MultinomialNB(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(solver='lbfgs') ,\n",
    "    #solver=sag est plus lent; donc j'ai choisi le plus rapide\n",
    "    DecisionTreeClassifier()\n",
    "]\n",
    "\n",
    "temps_train = []\n",
    "temps_test  = []\n",
    "rappel      = []\n",
    "precision   = []\n",
    "\n",
    "msg_train, msg_test, Y_train, Y_test = train_test_split(messages['texte'] ,\n",
    "                                                        messages['classe'],\n",
    "                                                        test_size    = 0.2, \n",
    "                                                        random_state = 0  )\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train          = count_vectorizer.fit_transform(msg_train).toarray()\n",
    "X_test           = count_vectorizer.transform    (msg_test ).toarray()\n",
    "\n",
    "\n",
    "for modele in modeles:\n",
    "    # ==================================\n",
    "    # ENTRAINEMENT \n",
    "    # ==================================\n",
    "    temps_debut = timeit.default_timer()\n",
    "    modele.fit(X_train, Y_train)\n",
    "    temps_train.append(timeit.default_timer() - temps_debut)\n",
    "    \n",
    "    # ==================================\n",
    "    # TEST \n",
    "    # ==================================\n",
    "    temps_debut = timeit.default_timer()\n",
    "    Y_pred      = modele.predict(X_test)\n",
    "    temps_test.append(timeit.default_timer() - temps_debut)\n",
    "    \n",
    "    # ==================================\n",
    "    # PERFORMANCE \n",
    "    # ==================================\n",
    "    # Ici, nous considérons une classification binaire avec une seule classe \"spam\" \n",
    "    # le classifieur ne sera pas jugé par sa capacité de détecter les non spams\n",
    "    precision.append(precision_score(Y_test, Y_pred, pos_label='spam'))\n",
    "    rappel   .append(recall_score   (Y_test, Y_pred, pos_label='spam'))\n",
    "\n",
    "    \n",
    "print('Fin') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.1. Temps d'entraînement et de test\n",
    "\n",
    "Combien de temps chaque algorithme prend pour entrainer le même dataset d'entrainement et combien de temps pour tester le même dataset de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithme</th>\n",
       "      <th>Temps d'entrainement</th>\n",
       "      <th>Temps de test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes Multinomial (NBM)</td>\n",
       "      <td>0.870354</td>\n",
       "      <td>0.051192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussien (NBG)</td>\n",
       "      <td>0.672426</td>\n",
       "      <td>0.273914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression logistique (RL)</td>\n",
       "      <td>1.651294</td>\n",
       "      <td>0.046925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arbre de decision (AD)</td>\n",
       "      <td>30.819348</td>\n",
       "      <td>0.031577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Algorithme  Temps d'entrainement  Temps de test\n",
       "0  Naive Bayes Multinomial (NBM)              0.870354       0.051192\n",
       "1     Naive Bayes Gaussien (NBG)              0.672426       0.273914\n",
       "2     Regression logistique (RL)              1.651294       0.046925\n",
       "3         Arbre de decision (AD)             30.819348       0.031577"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_noms = ['Naive Bayes Multinomial (NBM)', \n",
    "             'Naive Bayes Gaussien (NBG)'   , \n",
    "             'Regression logistique (RL)'   , \n",
    "             'Arbre de decision (AD)']\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Algorithme'            : algo_noms  ,\n",
    "    'Temps d\\'entrainement' : temps_train,\n",
    "    'Temps de test'         : temps_test\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "\n",
    "- Que remarquez-vous concernant le temps d'entrainement ? (ordonner les algorithmes)\n",
    "- Pourquoi nous avons eu ces résultats en se basant sur les algorithmes ? (discuter chaque algorithme vis-a-vis le temps d'entrainement)\n",
    "- Que remarquez-vous concernant le temps de test ? (ordonner les algorithmes)\n",
    "- Pourquoi nous avons eu ces résultats en se basant sur les algorithmes ? (discuter chaque algorithme vis-a-vis le temps de test)\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "- On peut remarquer que les algorithmes d'apprentissage rapide sont les méthodes Naive Bayes (Multinomial et Gaussien) et la Régression Logistique, tandis que l'arbre de décision est l'algorithme le plus lent en termes de temps d'entrainement. Ainsi, en ordonnant les algorithmes par temps d'entrainement croissant, on obtient :\n",
    "\n",
    "    * NBG\n",
    "    * NBM\n",
    "    * RL\n",
    "    * AD\n",
    "\n",
    "- Les temps d'entraînement obtenus pour chaque algorithme peuvent s'expliquer de la manière suivante :\n",
    "\n",
    "    * Naive Bayes Multinomial (NBM) : Il s'agit d'un modèle simple et rapide, qui est souvent utilisé comme point de départ pour la classification de texte. Il est basé sur l'hypothèse naïve que les différentes caractéristiques (mots dans ce cas) sont indépendantes les unes des autres. Il a besoin de calculer seulement la probabilité de chaque mot dans chaque classe, ce qui le rend très rapide à entraîner. Par conséquent, le temps d'entraînement est très court, comparé aux autres algorithmes.\n",
    "\n",
    "    * Naive Bayes Gaussien (NBG) : Ce modèle est également basé sur l'hypothèse naïve, mais il suppose que les différentes caractéristiques suivent une distribution Gaussienne. Il est souvent utilisé pour les problèmes de classification de données continues. Il nécessite le calcul de moyenne et de variance pour chaque caractéristique dans chaque classe, ce qui peut prendre plus de temps que pour le modèle multinomial. C'est pourquoi il est plus lent que le modèle multinomial.\n",
    "\n",
    "    * Régression logistique (RL) : La régression logistique est un algorithme de classification qui modélise la probabilité de la classe cible étant donné les caractéristiques. Elle utilise la fonction logistique pour calculer la probabilité. Elle est très flexible et peut être utilisée pour des problèmes de classification binaire ou multiclasse. Cependant, elle nécessite une recherche de paramètres pour ajuster le modèle à des données spécifiques, ce qui peut prendre plus de temps. Elle est également plus complexe que les modèles Naive Bayes, ce qui la rend plus lente.\n",
    "\n",
    "    * Arbre de décision (AD) : Les arbres de décision sont des modèles qui divisent récursivement l'espace des caractéristiques en sous-espaces plus petits, de manière à séparer les différentes classes. Ils sont souvent utilisés pour la classification de texte car ils peuvent facilement gérer des données avec un grand nombre de caractéristiques. Cependant, le processus de création de l'arbre est très coûteux en temps, car il nécessite de trouver la meilleure caractéristique pour diviser l'espace à chaque étape. Par conséquent, le temps d'entraînement pour les arbres de décision est généralement plus long que pour les autres algorithmes.\n",
    "\n",
    "    En résumé, le temps d'entrainement varie en fonction de la complexité de l'algorithme et de la taille de l'ensemble de données. Les algorithmes plus simples, tels que les Naive Bayes, sont plus rapides à entrainer que les algorithmes plus complexes, tels que la Régression logistique et l'arbre de décision.\n",
    "\n",
    "- En se basant sur les résultats, on remarque que l'algorithme d'arbre de décision (AD) est le plus rapide en termes de temps de test avec un temps de seulement 0.03 seconde, suivi de la régression logistique (RL) avec un temps de 0.048 seconde, puis le Naive Bayes Multinomial (NBM) avec un temps de 0.062 seconde, et enfin le Naive Bayes Gaussien (NBG) avec un temps de 0.268 seconde. Le temps est relativement plus long pour les algorithmes de Naive Bayes contrairement à AD et RL\n",
    "\n",
    "Donc, on peut ordonner les algorithmes en termes de temps de test dans l'ordre suivant :\n",
    "    * AD\n",
    "    * RL\n",
    "    * NBM\n",
    "    * NBG\n",
    "\n",
    "- Les temps de test sont essentiels pour mesurer la performance de chaque algorithme. Dans notre tableau, nous avons observé que l'arbre de décision a le temps de test le plus bas avec 0,03054, suivi par la régression logistique avec 0,04877, puis le Naive Bayes Multinomial avec 0,06289 et enfin le Naive Bayes Gaussien avec 0,26821.\n",
    "\n",
    "    L'arbre de décision a un temps de test plus faible car il prend des décisions simples en utilisant des règles conditionnelles sur les variables d'entrée. En revanche, la régression logistique a également un temps de test relativement faible car elle est basée sur des calculs simples de multiplication et d'addition, qui sont généralement rapides à effectuer. Les temps de test du Naive Bayes Multinomial et Gaussien sont plus élevés que ceux de l'arbre de décision et de la régression logistique, car ils nécessitent des calculs plus complexes pour estimer les probabilités des classes cibles.\n",
    "\n",
    "    En résumé, les temps de test des algorithmes dépendent des opérations et des calculs impliqués dans la prédiction des classes cibles pour de nouvelles données. Les algorithmes qui nécessitent des calculs plus complexes peuvent prendre plus de temps pour prédire les classes cibles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.2. Qualité de prédiction\n",
    "\n",
    "Comment chaque algorithme performe sur le dataset de test dans le cas de détection de spams (spam: est la classe positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithme</th>\n",
       "      <th>Rappel</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes Multinomial (NBM)</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.987179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussien (NBG)</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression logistique (RL)</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arbre de decision (AD)</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.913907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Algorithme    Rappel  Precision\n",
       "0  Naive Bayes Multinomial (NBM)  0.927711   0.987179\n",
       "1     Naive Bayes Gaussien (NBG)  0.891566   0.616667\n",
       "2     Regression logistique (RL)  0.855422   0.986111\n",
       "3         Arbre de decision (AD)  0.831325   0.913907"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Algorithme' : algo_noms,\n",
    "    'Rappel'     : rappel   ,\n",
    "    'Precision'  : precision\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les résultats**\n",
    "\n",
    "On remarque que Naive Bayes surpasse la régression logistique pour la détection de spams. \n",
    "- Est-ce que ceci preuve que Naive Bayes est meilleur que les autres algorithmes sur n'importe quel problème ?\n",
    "- Est-ce que ceci preuve que Naive Bayes peut donner de meilleurs résultats que les autres algorithmes sur des problèmes similaires ?\n",
    "- Pourquoi le modèle gaussien est moins performant que le multinomial en se basant sur la nature des deux algorithmes ?\n",
    "- Pourquoi le modèle gaussien est moins performant que le multinomial en se basant sur la nature du probleme/donnees ?\n",
    "\n",
    "**Réponse**\n",
    "\n",
    "- Non.(Les performances d'un algorithme dépendent de la nature du problème, de la qualité des données, de la taille de l'ensemble de données et d'autres facteurs. Il est donc important de tester plusieurs algorithmes et de comparer leurs performances sur un problème spécifique pour déterminer lequel est le plus approprié pour ce problème)\n",
    "\n",
    "- Oui\n",
    "\n",
    "- Le modèle gaussien suppose que les caractéristiques des données suivent une distribution gaussienne, également connue sous le nom de distribution normale. Cependant, dans le cas de la détection de spams, les caractéristiques des données ne suivent probablement pas une distribution gaussienne. Au contraire, il est plus probable que les données soient discrètes, c'est-à-dire que chaque caractéristique soit soit présente soit absente dans le message.\n",
    "Cela explique pourquoi le modèle multinomial, qui prend en compte les caractéristiques discrètes, est plus performant que le modèle gaussien, qui suppose une distribution continue.\n",
    "\n",
    "- Le modèle gaussien suppose que les caractéristiques suivent une distribution gaussienne, ce qui peut ne pas être le cas dans certains problèmes, en particulier pour les données textuelles où les caractéristiques sont souvent binaires ou catégorielles. Dans ce cas, le modèle gaussien peut ne pas être capable de capturer la structure sous-jacente des données aussi efficacement que le modèle multinomial, qui est mieux adapté pour les caractéristiques discrètes telles que les fréquences de mots dans le cas des données textuelles. Cela peut expliquer pourquoi le modèle multinomial est plus performant que le modèle gaussien dans la détection de spams, qui est un problème basé sur des données textuelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  _____    __                                              _               \n",
      " |_   _|  / _|                                            | |              \n",
      "   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \n",
      "   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \n",
      "  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \n",
      " |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \n",
      "                   __/ |                     __/ |                         \n",
      "                  |___/                     |___/                          \n",
      "  _     _       _            __                                            \n",
      " | |   | |     (_)          / _|                 _                         \n",
      " | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \n",
      " | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \n",
      " | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \n",
      "  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \n",
      "                                                |/                         \n",
      "                                                                           \n",
      "                                                                           \n",
      "                                                                           \n",
      "  _   _    ___    _   _      __ _   _ __    ___                            \n",
      " | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \n",
      " | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \n",
      "  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \n",
      "   __/ |                                                                   \n",
      "  |___/                                                                    \n",
      "                    _                                                __    \n",
      "                   | |                                            _  \\ \\   \n",
      "  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \n",
      " | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \n",
      " | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \n",
      " |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \n",
      "                                                                     /_/   \n",
      "                                                                           \n"
     ]
    }
   ],
   "source": [
    "print(\"  _____    __                                              _               \")\n",
    "print(\" |_   _|  / _|                                            | |              \")\n",
    "print(\"   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \")\n",
    "print(\"   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \")\n",
    "print(\"  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \")\n",
    "print(\" |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \")\n",
    "print(\"                   __/ |                     __/ |                         \")\n",
    "print(\"                  |___/                     |___/                          \")\n",
    "print(\"  _     _       _            __                                            \")\n",
    "print(\" | |   | |     (_)          / _|                 _                         \")\n",
    "print(\" | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \")\n",
    "print(\" | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \")\n",
    "print(\" | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \")\n",
    "print(\"  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \")\n",
    "print(\"                                                |/                         \")\n",
    "print(\"                                                                           \")\n",
    "print(\"                                                                           \")\n",
    "print(\"                                                                           \")\n",
    "print(\"  _   _    ___    _   _      __ _   _ __    ___                            \")\n",
    "print(\" | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \")\n",
    "print(\" | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \")\n",
    "print(\"  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \")\n",
    "print(\"   __/ |                                                                   \")\n",
    "print(\"  |___/                                                                    \")\n",
    "print(\"                    _                                                __    \")\n",
    "print(\"                   | |                                            _  \\ \\   \")\n",
    "print(\"  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \")\n",
    "print(\" | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \")\n",
    "print(\" | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \")\n",
    "print(\" |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \")\n",
    "print(\"                                                                     /_/   \")\n",
    "print(\"                                                                           \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
